<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Let Language Constrain Geometry:Vision–Language Models as Semantic and Spatial Critics for 3D Generation">
  <meta name="keywords" content="Diffusion Models, Text-to-3D, Vision-Language Model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>
    Let Language Constrain Geometry:Vision–Language Models as Semantic and Spatial Critics for 3D Generation
  </title>
  <script
    type="module"
    src="./static/js/model-viewer.min.js"
  ></script>
  <style>
    model-viewer {
      cursor: grab;
      display: flex;
      height: 100%;
      width: 100%;
      overflow: hidden;
      position: relative;
      user-select: none;
    }
  </style>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bootstrap.min.css">
  <link rel="stylesheet" href="./static/css/style.css">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
<!--  <link rel="icon" href="./static/images/favicon.svg">-->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript"
  src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  <style>
        .bold-and-large {
            font-weight: bold; /* 加粗 */
            font-size: 24px; /* 加大字体大小，你可以根据需要调整这个值 */
        }
    </style>
</head>
<body>

<style>
  .container {
    max-width: 1100px;
    margin: 0 auto;
  }

  /* 整体缩放为80% */
  body {
    margin: 0;
    padding: 0;
  }

  .scale-wrapper {
    transform: scale(0.8);
    transform-origin: top center;
    width: 100vw;
    margin: 0 auto;
  }

  /* Abstract 样式调整：字体放大，两行间距适当增加 */
  .abstract-text {
    font-size: 1.25rem;
    line-height: 1.7;
  }

  /* 视频布局样式：确保左右区域等高，美观间距与字幕占位 */
  .video-row {
    display: flex;
    gap: 20px;
    align-items: stretch;
  }
  /* 固定整个视频行高度，方便行内元素按比例布局 */
  :root { --video-total-height: 540px; }
  .video-row { height: var(--video-total-height); }

  .video-left .box,
  .video-right .box {
    height: 600px; /* 整体高度：调整为600px */
    box-sizing: border-box;
    padding: 8px;
  }

  .video-caption {
    min-height: 5.2em;
    margin-top: 8px;
    font-size: 0.95rem;
    line-height: 1.4;
  }

  /* 使用 grid 布局使右侧严格对齐为：上两列、下三列 */
  .video-right .box {
    display: grid;
    grid-template-rows: 1fr 1fr;
    gap: 10px;
    height: 100%;
  }

  .video-right .top-row {
    display: grid;
    grid-template-columns: repeat(3, 1fr);
    gap: 10px;
  }

  .video-right .bottom-row {
    display: grid;
    grid-template-columns: repeat(3, 1fr);
    gap: 10px;
  }

  .video-right .top-row > div,
  .video-right .bottom-row > div {
    flex: 1;
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: stretch;
  }

  .video-right video,
  .video-right img {
    width: 100%;
    height: auto;
    flex: 1 1 auto;
    object-fit: cover;
    border-radius: 4px;
    box-shadow: 0 6px 18px rgba(0,0,0,0.08);
  }

  /* 去掉左右区域外部白框（只影响视频区域的 box） */
  .video-left .box,
  .video-right .box {
    background: transparent;
    box-shadow: none;
    border: none;
    padding: 0;
  }

  /* 右侧视频与文字间距更大，确保视频高度一致 */
  .video-right .video-caption {
    min-height: 1.8em;
    margin-top: 12px;
    font-size: 0.9rem;
  }

  /* 限制左侧 caption 最大高度，避免撑高列（如果文字过多会出现滚动） */
  .video-left .video-caption {
    max-height: 160px;
    overflow: auto;
    padding-top: 10px;
  }

  /* 右侧 caption 更紧凑，留更多高度给视频 */
  .video-right .video-caption {
    min-height: 1.6em;
    margin-top: 6px;
    font-size: 0.85rem;
  }

  .video-left .box {
    display: flex;
    flex-direction: column;
  }

  .video-left img {
    width: 100%;
    flex: 1 1 auto;
    object-fit: cover;
    border-radius: 4px;
    box-shadow: 0 6px 18px rgba(0,0,0,0.08);
  }

  /* 左侧大caption与图片同宽并居中 */
  .video-left .video-caption {
    width: 100%;
    max-width: none;
    box-sizing: border-box;
    margin: 0;
    padding: 0;
    margin-left: 0%;
    text-align: center;
  }

  /* 给视频区域底部多留些空白，避免被下方标题覆盖 */
  .content .video-row {
    margin-bottom: 48px;
  }
</style>


<div class="scale-wrapper">
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Let Language Constrain Geometry:<br>Vision–Language Models as Semantic and Spatial Critics for 3D Generation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=M6bEs8IAAAAJ&hl=en&oi=ao">Weimin Bai</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=moOB0R4AAAAJ&hl=en&oi=ao">Yubo Li</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://pkulwj1994.github.io/">Weijian Luo</a><sup>2</sup>,
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=WUMu1KkAAAAJ&hl=en&oi=ao">Zeqiang Lai</a><sup>3</sup>,
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=7Gqp6FsAAAAJ&hl=en&oi=ao">Yequan Wang</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://wenzhengchen.github.io/">Wenzheng Chen</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="http://users.cms.caltech.edu/~hesun/">He Sun</a><sup>1✉</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Peking University,</span>
            <span class="author-block"><sup>2</sup>Xiaohongshu Inc</span>
            <span class="author-block"><sup>3</sup>MMLab, CUHK</span>
            <span class="author-block"><sup>4</sup>BAAI, Beijing</span>
            <span class="author-block"><sup>✉</sup>Corresponding Author</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
<!--              &lt;!&ndash; PDF Link. &ndash;&gt;-->
<!--              <span class="link-block">-->
<!--                <a href="https://arxiv.org/pdf/2011.12948"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fas fa-file-pdf"></i>-->
<!--                  </span>-->
<!--                  <span>Paper</span>-->
<!--                </a>-->
<!--              </span>-->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2511.14271"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
<!--              &lt;!&ndash; Video Link. &ndash;&gt;-->
<!--              <span class="link-block">-->
<!--                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fab fa-youtube"></i>-->
<!--                  </span>-->
<!--                  <span>Video</span>-->
<!--                </a>-->
<!--              </span>-->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ai4imaging/vlm3d"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
<!--              &lt;!&ndash; Dataset Link. &ndash;&gt;-->
<!--              <span class="link-block">-->
<!--                <a href="https://github.com/google/nerfies/releases/tag/0.1"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="far fa-images"></i>-->
<!--                  </span>-->
<!--                  <span>Data</span>-->
<!--                  </a>-->
<!--              </span>-->
            </div>
<!--      <div>-->
<!--        <span class="center"><img src="./static/images/img-teaser.jpg" style="width:850px;"></span>-->
<!--      </div>-->
          </div>
        </div>
      </div>
    </div>
  </div>


</section>



<section class="" style="padding-bottom: 3rem">
  <div class="container is-max-desktop">
      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Method</h2>
  <!--        <div class="publication-video">-->
  <!--          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"-->
  <!--                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>-->
  <!--        </div>-->
          <div>
          <span class="center"><img src="./static/images/vlm3d-overview-cvpr-2_01.png" style="width:1800px;"></span><br>
            <!-- <p class="bold-and-large">E-step, draw samples from LDMs: </p>
              <span class="center"><img src="./static/images/img_13.png" style="width:550px;"></span><br>
            <br>
            <p class="bold-and-large">M-step, update forward model through MAP:
                <span class="center"><img src="./static/images/img_14.png" style="width:550px;"></span><br>
            </p>
            <br>
            * Further details can be found in the paper. -->
          </div>
        </div>
      </div>
      <!--/ Paper video. -->
    </div>
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
    <div class="column is-three-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified abstract-text">
          <p>
            Text-to-3D generation has advanced rapidly, yet state-of-theart models, encompassing both optimization-based and feedforward architectures, still face two fundamental limitations.
            First, they struggle with coarse semantic alignment, often
            failing to capture fine-grained prompt details. Second, they
            lack robust 3D spatial understanding, leading to geometric
            inconsistencies and catastrophic failures in part assembly
            and spatial relationships. To address these challenges, we
            propose VLM3D, a general framework that repurposes large
            vision-language models (VLMs) as powerful, differentiable
            semantic and spatial critics. Our core contribution is a dualquery critic signal derived from the VLM’s "Yes/No" logodds, which assesses both semantic fidelity and geometric
            coherence. We demonstrate the generality of this guidance
            signal across two distinct paradigms: (1) As a reward objective for optimization-based pipelines, VLM3D significantly
            outperforms existing methods on standard benchmarks. (2)
            As a test-time guidance module for feed-forward pipelines,
            it actively steers the iterative sampling process of SOTA native 3D models to correct severe spatial errors. VLM3D
            establishes a principled and generalizable path to inject
            the VLM’s rich, language-grounded understanding of both
            semantics and space into diverse 3D generative pipelines.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Video Results</h2>
        <div class="content">
          <!-- 主要布局：左边大视频，右边小视频网格 -->
          <div class="columns video-row">
            <!-- 左边：大正方形视频区域 -->
            <div class="column is-5 video-left">
              <div class="box" style="height: 100%;">
                <img src="./static/images/sailor.gif" style="width: 100%; height: 100%; object-fit: cover;" alt="Sailor Animation">
                <p class="has-text-centered video-caption" style="font-weight: bold;">
                  A Navy sailor in a dark uniform—cap, jacket, and trousers—leaning 
                  forward at the waist to press his lips against a nurse in a crisp 
                  white dress; his left hand cradles the back of her head and
                  his right arm wraps around her
                  waist, while she arches backward
                  in a dramatic dip with one leg
                  lifted and her arms outstretched
                  for balance.
                  </p>
              </div>
            </div>

            <!-- 右边：小视频网格区域（上：3个1:1视频，下：3个1:1视频） -->
            <div class="column is-7 video-right">
              <div class="box" style="height: 100%;">
                <!-- 上半部分：两个 3:1 宽高比的视频 -->
                <div class="top-row">
                  <div>
                    <video controls autoplay muted loop style="width: 100%; height: 100%; object-fit: cover;">
                      <source src="./static/Video/vlm3d/An_ancient,_weathered_statue,_now_covered_in_a_blanket_of_moss/1.mp4" type="video/mp4">
                    </video>
                    <p class="has-text-centered video-caption" style="margin-top: 8px; font-size: 0.9em;">An ancient, weathered statue, now covered in a blanket of moss</p>
                  </div>
                  <div>
                    <video controls autoplay muted loop style="width: 100%; height: 100%; object-fit: cover;">
                      <source src="./static/Video/vlm3d/An_ice_cream_scoop_that_serves_up_scoops_of_cloud_fluff_instead_of_ice_cream/2.mp4" type="video/mp4">
                    </video>
                    <p class="has-text-centered video-caption" style="margin-top: 8px; font-size: 0.9em;">An ice cream scoop that serves up scoops of cloud fluff instead of ice cream</p>
                  </div>
                  <div>
                    <video controls autoplay muted loop style="width: 100%; height: 100%; object-fit: cover;">
                      <source src="./static/Video/vlm3d/Spotted_ladybug_crawling_on_a_green_leaf/3.mp4" type="video/mp4">
                    </video>
                    <p class="has-text-centered video-caption" style="margin-top: 8px; font-size: 0.9em;">Spotted ladybug<br>crawling on<br>a green leaf</p>
                  </div>
                </div>

                <!-- 下半部分：三个 1:1 的视频 -->
                <div class="bottom-row">
                  <div>
                    <img src="./static/images/a_bedside_table.gif" alt="A bedside table" style="width:100%; height:100%; object-fit:cover;">
                    <p class="has-text-centered video-caption" style="margin-top: 5px; font-size: 0.8em;">A bedside table</p>
                  </div>
                  <div>
                    <img src="./static/images/a_carry_on_bag.gif" alt="A carry-on bag" style="width:100%; height:100%; object-fit:cover;">
                    <p class="has-text-centered video-caption" style="margin-top: 5px; font-size: 0.8em;">A carry-on bag</p>
                  </div>
                  <div>
                    <img src="./static/images/An_electric_grill.gif" alt="An electric grill" style="width:100%; height:100%; object-fit:cover;">
                    <p class="has-text-centered video-caption" style="margin-top: 5px; font-size: 0.8em;">An electric grill</p>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <!-- Comparison with Stable Diffusion baselines -->
        <h2 class="title is-3">Comparison with Baselines on the GPTEval3D Benchmark</h2>
        <div class="content has-text-centered">
          <div style="margin: 20px 0;">
            <img src="./static/images/vlm3d-figure3.png" style="width: 85%; margin-bottom: 20px;">
            <p>VLM3D outperforms baseline methods in geometric consistency, 3D plausibility, texture richness, and text alignment.</p>
          </div>
        </div>

        <!-- Comparison with MVDiffusion baselines -->
        <h2 class="title is-3">Comparison with Baselines based on MVDiffusion and reward model</h2>
        <div class="content has-text-centered">
          <div style="margin: 20px 0;">
            <img src="./static/images/vlm3d-figure4.png" style="width: 90%; margin-bottom: 20px;">
            <p>VLM3D outperforms these reward-involved methods in semantic fidelity while retaining high perceptual quality.</p>
          </div>
        </div>

        <!-- Comparison of VLM3D with feed-forward baselines. -->
        <h2 class="title is-3">Comparison of VLM3D with feed-forward baselines.</h2>
        <div class="content has-text-centered">
          <div style="margin: 20px 0;">
            <img src="./static/images/vlm3d-figure5.png" style="width: 90%; margin-bottom: 20px;">
            <p>VLM3D outperforms feed-forward baselines in semantic fidelity while retaining high perceptual quality.</p>
          </div>
        </div>

        <h2 class="title is-3">Sensitivity Analysis to Text Perturbations</h2>
        <div class="content has-text-centered">
          <div style="margin: 20px 0;">
            <img src="./static/images/vlm3d-figure6.png" style="width: 95%; margin-bottom: 20px;">
            <p>VLM3D accurately changes clothing color (first row), and updates spatial relations (second row), </p>demonstrating
              its better semantic understanding than baselines.</p>
          </div>
        </div>

        <h2 class="title is-3">Ablation of Geometric Query and Multi-View Input</h2>
        <div class="content has-text-centered">
          <div style="margin: 20px 0;">
            <img src="./static/images/vlm3d-figure7.png" style="width: 95%; margin-bottom: 20px;">
            <p>We assess the impact of (a) removing the explicit geometry-consistency
              query from the VLM prompt and (b) using a single view instead of multi-view images. Omitting either component degrades 3D quality—leading to Janus-face artifacts, floating parts, and fractured surfaces. </p>Each row uses a different diffusion backbone: the top employs
              Stable Diffusion 2-1, while the bottom uses MVDream.</p>
          </div>
        </div>

    </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Additional results generated by our optimization-based VLM3D</h2>
        <div class="content has-text-centered">
          <div style="margin: 20px 0;">
            <img src="./static/images/addition_1.png" style="width: 90%; margin-bottom: 20px;" alt="Additional VLM3D Results">
            <p>Additional results generated by our optimization-based VLM3D.</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Additional results generated by our optimization-based VLM3D</h2>
        <div class="content has-text-centered">
          <div style="margin: 20px 0;">
            <img src="./static/images/addition_2.png" style="width: 90%; margin-bottom: 20px;" alt="Additional VLM3D Results">
            <p>Additional results generated by our optimization-based VLM3D.</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Additional results generated by our optimization-based VLM3D</h2>
        <div class="content has-text-centered">
          <div style="margin: 20px 0;">
            <img src="./static/images/addition_3.png" style="width: 90%; margin-bottom: 20px;" alt="Additional VLM3D Results">
            <p>Additional results generated by our feed-forward-based VLM3D.</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Additional results generated by our optimization-based VLM3D</h2>
        <div class="content has-text-centered">
          <div style="margin: 20px 0;">
            <img src="./static/images/addition_4.png" style="width: 90%; margin-bottom: 20px;" alt="Additional VLM3D Results">
            <p>Additional results generated by our feed-forward-based VLM3D.</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Quantitative Results</h2>
        <div class="content has-text-centered">
          <p class="has-text-justified">
            <strong>Quantitative Results on 110 Prompts from the GPTEval3D Benchmark.</strong> We compute all six GPTEval3D metrics—text alignment, 3D plausibility, texture–geometry coherence, geometry details, texture details, and overall score—to comprehensively evaluate 3D generation quality. VLM3D achieves the highest score on every metric, demonstrating its superior performance.
          </p>
          <div class="table-container" style="margin: 20px 0;">
            <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth">
              <thead>
                <tr>
                  <th rowspan="2">Method</th>
                  <th colspan="6">Prompts from GPTEval3D</th>
                </tr>
                <tr>
                  <th>Alignment</th>
                  <th>Plausibility</th>
                  <th>T-G Coherency</th>
                  <th>Geo Details</th>
                  <th>Tex Details</th>
                  <th>Overall</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>DreamFusion</td>
                  <td>1000.0</td>
                  <td>1000.0</td>
                  <td>1000.0</td>
                  <td>1000.0</td>
                  <td>1000.0</td>
                  <td>1000.0</td>
                </tr>
                <tr>
                  <td>DreamGaussian</td>
                  <td>1100.6</td>
                  <td>953.6</td>
                  <td>1158.6</td>
                  <td>1126.2</td>
                  <td>1130.8</td>
                  <td>951.4</td>
                </tr>
                <tr>
                  <td>Fantasia3D</td>
                  <td>1067.9</td>
                  <td>891.9</td>
                  <td>1006.0</td>
                  <td>1109.3</td>
                  <td>1027.5</td>
                  <td>933.5</td>
                </tr>
                <tr>
                  <td>Instant3D</td>
                  <td>1200.0</td>
                  <td>1087.6</td>
                  <td>1152.7</td>
                  <td>1152.0</td>
                  <td>1181.3</td>
                  <td>1097.8</td>
                </tr>
                <tr>
                  <td>Latent-NeRF</td>
                  <td>1222.3</td>
                  <td>1144.8</td>
                  <td>1156.7</td>
                  <td>1180.5</td>
                  <td>1160.8</td>
                  <td>1178.7</td>
                </tr>
                <tr>
                  <td>Magic3D</td>
                  <td>1152.3</td>
                  <td>1000.8</td>
                  <td>1084.4</td>
                  <td>1178.1</td>
                  <td>1084.6</td>
                  <td>961.7</td>
                </tr>
                <tr>
                  <td>ProlificDreamer</td>
                  <td>1261.8</td>
                  <td>1058.7</td>
                  <td>1152.0</td>
                  <td>1246.4</td>
                  <td>1180.6</td>
                  <td>1012.5</td>
                </tr>
                <tr>
                  <td>SyncDreamer</td>
                  <td>1041.2</td>
                  <td>968.8</td>
                  <td>1083.1</td>
                  <td>1064.2</td>
                  <td>1045.7</td>
                  <td>963.5</td>
                </tr>
                <tr>
                  <td>MVDream</td>
                  <td>1270.5</td>
                  <td>1147.5</td>
                  <td>1250.6</td>
                  <td>1324.9</td>
                  <td>1255.5</td>
                  <td>1097.7</td>
                </tr>
                <tr>
                  <td>DreamReward<sup>1</sup></td>
                  <td>1287.5</td>
                  <td>1195.0</td>
                  <td>1254.4</td>
                  <td>1295.5</td>
                  <td>1261.6</td>
                  <td>1193.3</td>
                </tr>
                <tr>
                  <td>DreamDPO</td>
                  <td>1298.9</td>
                  <td>1171.9</td>
                  <td>1276.4</td>
                  <td>1373.25</td>
                  <td>1296.9</td>
                  <td>1203.1</td>
                </tr>
                <tr>
                  <td><strong>VLM3D (Ours)</strong></td>
                  <td><strong>1365.5</strong></td>
                  <td><strong>1293.7</strong></td>
                  <td><strong>1365.4</strong></td>
                  <td><strong>1419.0</strong></td>
                  <td><strong>1368.7</strong></td>
                  <td><strong>1268.6</strong></td>
                </tr>
              </tbody>
            </table>
          </div>
          <p class="has-text-justified" style="font-size: 0.9em;">
            <sup>1</sup> Our metrics differ from those reported in the original DreamReward paper because GPT-4V has been deprecated in GPTEval3D, so we instead use GPT-4o-mini.
          </p>
          <p class="has-text-justified">
            <strong>Quantitative Results for feed-forward pipelines on 24 prompts.</strong> VLM3D boosts both semantic and geometric quality.
          </p>
          <div class="table-container" style="margin: 20px 0;">
            <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth">
              <thead>
                <tr>
                  <th>Method</th>
                  <th>CLIP-D ↓</th>
                  <th>FID ↓</th>
                  <th>CLIP-FID ↓</th>
                  <th>Geo. ↓</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>CLAY</td>
                  <td>0.22</td>
                  <td>310.3</td>
                  <td>53.11</td>
                  <td>0.63</td>
                </tr>
                <tr>
                  <td>Hunyuan3D</td>
                  <td>0.23</td>
                  <td>338.6</td>
                  <td>54.01</td>
                  <td>0.58</td>
                </tr>
                <tr>
                  <td><strong>VLM3D (Ours)</strong></td>
                  <td><strong>0.19</strong></td>
                  <td><strong>274.9</strong></td>
                  <td><strong>45.79</strong></td>
                  <td><strong>0.49</strong></td>
                </tr>
              </tbody>
            </table>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{bai2025letlanguageconstraingeometry,
      title={Let Language Constrain Geometry: Vision-Language Models as Semantic and Spatial Critics for 3D Generation}, 
      author={Weimin Bai and Yubo Li and Weijian Luo and Zeqiang Lai and Yequan Wang and Wenzheng Chen and He Sun},
      year={2025},
      eprint={2511.14271},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2511.14271}, 
    }
}</code></pre>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
<!--          <p>-->
<!--            This website is licensed under a <a rel="license"-->
<!--                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative-->
<!--            Commons Attribution-ShareAlike 4.0 International License</a>.-->
<!--          </p>-->
          <p>
            The website template is borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> and licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
</div>

</body>
</html>
